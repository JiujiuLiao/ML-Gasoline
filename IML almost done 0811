# in case regr.ksvm not found execute following comments
# 
#options(repos = c(
#  mlrorg = "https://mlr-org.r-universe.dev",
#  CRAN = "https://cloud.r-project.org/"
#))
#install.packages("mlr3extralearners")
#install.packages("mboost")
#install.packages("nett")

#mlr_learners$get("regr.glm")
#mlr_learners$get("regr.nnet")
#mlr_learners$get("regr.glmboost")


library(dplyr)
library(ggplot2)
library(mlr3)
library(mlr3learners) #added for regr.glm and regr.nnet, later can be deleted
library(mlr3verse)
library(mlr3tuning)
library(mlr3extralearners)
library(mlr3hyperband)
library(mlr3viz)
library(ranger)
library(rpart)
library(kknn)
library(kernlab)
library(paradox)


#set work directory
setwd("C:/Users/jiuji/OneDrive/Desktop/study/Advanced method in data analysis/Applications in Data Analytics")

df <- read.csv("aggregated_data_Saxony_13-15_big_brands.csv",row.names = 1)
sapply(lapply(df, unique), length)

# make up a new subset for ML task(exclude )
df.subset.e5 = df[,-which(colnames(df) %in% c("diesel_price","e10_price"))]
str(df.subset.e5)
rm(df)
colnames(df.subset.e5)
#set character variables into factor so that regression tree can work
df.subset.e5[, c("brand", "settlement","day","hour", "krs_name_s")] <- lapply(
  df.subset.e5[, c("brand", "settlement","day","hour", "krs_name_s")], as.factor)

#Partition data 
train_data <- df.subset.e5 %>% filter(day %in% c("Tue","Wed"))
train_data <- train_data[,-which(colnames(train_data) %in% c("day"))]
test_data <- df.subset.e5 %>% filter(day %in% c("Thu"))
test_data <- test_data[,-which(colnames(test_data) %in% c("day"))]

#count unique values for each variable
sapply(lapply(train_data, unique), length)


##################ML process ################
# load a task
tsk_e5.price = as_task_regr(train_data, target = "e5_price",id= "id")
print(tsk_e5.price)

# Define learners and resampling strategy
learners <- list(
  lrn("regr.rpart"),
  lrn("regr.kknn", k = 10L),
  lrn("regr.featureless"),
  lrn("regr.ranger"),
  lrn("regr.glm"),
  lrn("regr.nnet"),
  lrn("regr.ksvm")
)

resampling <- rsmp("cv", folds = 5)
resampling$instantiate(tsk_e5.price)


# Benchmark learners
design <- benchmark_grid(
  tasks = tsk_e5.price,
  learners = learners,
  resamplings = resampling
)

# Aggregate the benchmark results by RMSE instead of MSE
bmr <- benchmark(design,store_models = TRUE) 
bmr_rmse <- bmr$aggregate(msr("regr.rmse"))
print(bmr_rmse)

#Visualize the Comparison of Benchmark (Boxplot)
plot_benchmark <- autoplot(bmr, measure = msr("regr.rmse")) +
  theme_bw() +
  ylab("Regression RMSE") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12))
print(plot_benchmark)

# Save the plot
ggsave(filename = "benchmark_results_test.df.png", plot = plot_benchmark, width = 8, height = 6)


#---------------------Check if is it Overfitting using the test data--------------------------------
#Check if is it Overfitting using the test data

#define task
tsk_regr.test <- as_task_regr(train_data, target = "e5_price",id="id")
tsk_regr.test

# Measurement
measures = msrs("regr.rmse")

##### decision tree

model_rpart <- lrn("regr.rpart")$train(tsk_regr.test)
model_rpart

predictions_rpart <- model_rpart$predict_newdata(test_data)
model_rpart$predict_newdata(test_data)$score(measures)

#-------------------Check the Performance of Untuned Learners Using Test Dataset--------------
##### kknn

model_kknn <- lrn("regr.kknn")$train(tsk_regr.test)
model_kknn

predictions_kknn <- model_kknn$predict_newdata(test_data)
print(predictions_kknn)
model_kknn$predict_newdata(test_data)$score(measures)

##### regr.ranger learner-----------

model_ranger <- lrn("regr.ranger")$train(tsk_regr.test)
model_ranger

predictions_ranger <- model_ranger$predict_newdata(test_data)
print(predictions_ranger)

model_ranger$predict_newdata(test_data)$score(measures)


#---------- regr.glm learner-----------
#define task
tsk_regr.glm <- as_task_regr(train_data, target = "e5_price",id="id")
tsk_regr.glm
#build a model
model_glm <- lrn("regr.glm")$train(tsk_regr.test)
model_glm
# Predict on the test data using the trained glm model
predictions_glm <- model_glm$predict_newdata(test_data)
print(predictions_glm)

# make and score predictions
model_glm$predict_newdata(test_data)$score(measures)


#----------5. regr.nnet learner-----------
#build a model
model_nnet <- lrn("regr.nnet")$train(tsk_regr.test)
model_nnet
# Predict on the test data using the trained nnet model
predictions_nnet <- model_nnet$predict_newdata(test_data)
print(predictions_nnet)

# make and score predictions
model_nnet$predict_newdata(test_data)$score(measures)


#-----------------------Hyperparameter Optimization--------------------------
#Random Forest,KKNN, Decision Tree optimization
#search space by default setting
lts_rpart = lts("regr.rpart.default")
lts_kknn = lts("regr.kknn.default")
lts_ranger = lts("regr.ranger.default")


# Define tuning instances
tuner <- mlr3tuning::tnr("grid_search")
tuner

at_rpart <- AutoTuner$new(
  learner = lrn("regr.rpart"),
  resampling = rsmp("cv", folds = 5),
  measure = msr("regr.rmse"),
  search_space = lts_rpart,
  terminator = trm("evals", n_evals = 5),
  tuner = tuner
)

at_kknn <- AutoTuner$new(
  learner = lrn("regr.kknn"),
  resampling = rsmp("cv", folds = 5),
  measure = msr("regr.rmse"),
  search_space = lts_kknn,
  terminator = trm("evals", n_evals = 5),
  tuner = tuner
)

at_ranger <- AutoTuner$new(
  learner = lrn("regr.ranger"),
  resampling = rsmp("cv", folds = 5),
  measure = msr("regr.rmse"),
  search_space = lts_ranger,
  terminator = trm("evals", n_evals = 3),
  tuner = tuner
)



#-------------------Check the Performance of Tuned Learners Using Test Dataset--------------
###### tuned rpart

at_rpart$train(tsk_regr.test)
at_rpart$predict_newdata(test_data)$score(measures)

###### tuned kknn

at_kknn$train(tsk_regr.test)
at_kknn$predict_newdata(test_data)$score(measures)

##### tuned random forest (regr.ranger)
at_ranger$train(tsk_regr.test)
at_ranger$predict_newdata(test_data)$score(measures)


###### featureless

model_featureless <- lrn("regr.featureless")$train(tsk_regr.test)
model_featureless

predictions_featureless <- model_featureless$predict_newdata(test_data)
model_featureless$predict_newdata(test_data)$score(measures)


# Define learners with Hyperparameter tuning
learners_total <- list(lrn("regr.rpart"),
                       at_rpart, 
                       lrn("regr.kknn", k = 10L),
                       at_kknn, 
                       lrn("regr.ranger"),
                       at_ranger,
                       lrn("regr.featureless")
)

#Define outer resampling
outer_resampling <- rsmp("cv", folds = 3)

# Perform nested resampling
design_all.learners <- benchmark_grid(
  tasks = tsk_e5.price,
  learners = learners_total,
  resamplings = outer_resampling
)

bmr_all.lrs <- benchmark(design_all.learners)
bmr_rmse_all.lrs <- bmr_all.lrs$aggregate(msr("regr.rmse"))

# Visual comparison of the benchmark results
plot_benchmark_all.lrs <- autoplot(bmr_all.lrs, measure = msr("regr.rmse")) +
  theme_bw() +
  ylab("Regression RMSE") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12))
print(plot_benchmark_all.lrs)
# Save the plot
ggsave(filename = "benchmark_results_all.lrs.png", plot = plot_benchmark_all.lrs, width = 8, height = 6)


#----------------------------Using the best after-tuned learner(regr.ranger) to train a model -----------------------
#Train full data set using the best learner(tuned ranger forest) that we got above
#train_data <- test.df %>% filter(day %in% c("Fri", "Sat", "Sun", "Mon", "Tue"))
#test_data <- test.df %>% filter(day %in% c("Wed", "Thu"))


#define task
#tsk_at.ranger <- as_task_regr(train_data, target = "e5_price",id="id")
#tsk_at.ranger

#define the model
model_at_ranger <- at_ranger$train(tsk_e5.price)


# Train the learners and predict on the test data, mainly to visualize the data set
library(purrr)  # For using the map function
learners_ranger.at_ranger <- list(lrn("regr.ranger"),at_ranger)

predictions <- map_df(learners_ranger.at_ranger, function(learner) {
  learner$train(tsk_e5.price)
  prediction <- learner$predict_newdata(test_data)
  data.frame(
    actual = test_data$e5_price,
    predicted = prediction$response,
    learner = learner$id
  )
})

# Plot predictions vs actual values
plot_prediction.actual <- ggplot(predictions, aes(x = actual, y = predicted, color = learner)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Predictions vs Actual Values",
       x = "Actual Values",
       y = "Predicted Values") +
  theme_minimal()
print(plot_prediction.actual)

ggsave(filename = "Prediction vs Actual values.png", plot = plot_prediction.actual, width = 8, height = 6)

#Plot residuals
predictions_residual <- predictions %>%    #add residual column to prediction data frame
  mutate(residual = actual - predicted)

plot_residual.actual <- ggplot(predictions_residual, aes(x = actual, y = residual, color = learner)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs Actual Values",
       x = "Actual Values",
       y = "Residuals") +
  theme_minimal()
print(plot_residual.actual)

ggsave(filename = "Residual vs Actual values.png", plot = plot_residual.actual, width = 8, height = 6)

#Plot density of residuals
plot_Den.residual <- ggplot(predictions_residual, aes(x = residual, fill = learner)) +
  geom_density(alpha = 0.5) +
  labs(title = "Density Plot of Residuals",
       x = "Residuals",
       y = "Density") +
  theme_minimal()
print(plot_Den.residual)
ggsave(filename = "Density of residual.png", plot = plot_Den.residual, width = 8, height = 6)

#remove data set to save space
rm(df.subset.e5)
rm(test_data)

#--------------------------------Interpretable Machine Learning-------------------------
#install.packages("iml")
#install.packages("Matrix")
library(iml)
library(glmnet)
# Create a Predictor object.
predictor <- Predictor$new(
  at_ranger,
  data = tsk_e5.price$data(),
  y = tsk_e5.price$target_names
)

#feature importance
importance <- FeatureImp$new(predictor, loss = "rmse")
plot_Imp <- importance$plot()
ggsave(filename = "feature_importance.png", plot = plot_Imp, width = 8, height = 6)

#pdp plot
pdp_d_road <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_road",
  method = "pdp"
); 
plot_d_road <- pdp_d_road$plot()
plot(plot_d_road)
ggsave(filename = "pdp_d_road.png", plot = plot_d_road, width = 8, height = 6)


#pdp_hour <- FeatureEffect$new(
 # predictor = predictor,
#  feature = "hour",
 # method = "pdp"
#); 
#plot_hour <- pdp_hour$plot()
#plot(plot_hour)

pdp_d_1 <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_1",
  method = "pdp"
); 
plot_d1 <- pdp_d1$plot()
plot(plot_d1)
ggsave(filename = "pdp_d1.png", plot = plot_d1, width = 8, height = 6)




#ALE PLOTS
#ale_freq <- FeatureEffect$new(
 # predictor = predictor,
#  feature = "freq",
#  method = "ale"
#); 
#plot_ale.freq <- ale_freq$plot()
#plot(plot_ale.freq)


ale_d_city <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_city",
  method = "pdp"
); 
plot_ale_d_city <- ale_d_city$plot()
plot(plot_ale_d_city)
ggsave(filename = "plot_ale_d_city.png", plot = plot_ale_d_city, width = 8, height = 6)


ale_d_1 <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_1",
  method = "ale"
); ale_d_1$plot()


ale_hour <- FeatureEffect$new(
  predictor = predictor,
  feature = "hour",
  method = "ale"
); ale_hour$plot()

ale_road <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_road",
  method = "ale"
); ale_road$plot()

ale_region <- FeatureEffect$new(
  predictor = predictor,
  feature = "region",
  method = "ale"
); ale_region$plot()



ale_day <- FeatureEffect$new(
  predictor = predictor,
  feature = "day",
  method = "ale"
); ale_day$plot()

ale_brand <- FeatureEffect$new(
  predictor = predictor,
  feature = "brand",
  method = "ale"
); ale_brand$plot()

ale_weekend <- FeatureEffect$new(
  predictor = predictor,
  feature = "weekend",
  method = "ale"
); ale_weekend$plot()

ale_settlement <- FeatureEffect$new(
  predictor = predictor,
  feature = "settlement",
  method = "ale"
); ale_settlement$plot()

ale_count_part <- FeatureEffect$new(
  predictor = predictor,
  feature = "count_part",
  method = "ale"
); ale_count_part$plot()

#plot all ALE at once   #cannot work,since count_part only is west Germany
effs <- FeatureEffects$new(predictor, grid.size = 10)
plot(effs)

#ice plots
ice_freq <- FeatureEffect$new(
  predictor = predictor,
  feature = "freq",
  method = "pdp+ice"
); 
plot_ice.freq <- ice_freq$plot()
plot(plot_ice.freq)
ggsave(filename = "plot_ice.freq.png", plot = plot_ice.freq, width = 8, height = 6)


ice_d_1 <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_1",
  method = "pdp+ice"
); ice_d_1$plot()

ice_hour <- FeatureEffect$new(
  predictor = predictor,
  feature = "hour",
  method = "pdp+ice"
); ice$plot()

ice_d_road <- FeatureEffect$new(
  predictor = predictor,
  feature = "d_road",
  method = "pdp+ice"
); ice_d_road$plot()

ice_region <- FeatureEffect$new(
  predictor = predictor,
  feature = "region",
  method = "pdp+ice"
); ice_region$plot()



ice_day <- FeatureEffect$new(
  predictor = predictor,
  feature = "day",
  method = "pdp+ice"
); ice_day$plot()


ice_brand <- FeatureEffect$new(
  predictor = predictor,
  feature = "brand",
  method = "pdp+ice"
); ice_brand$plot()


ice_weekend <- FeatureEffect$new(
  predictor = predictor,
  feature = "weekend",
  method = "pdp+ice"
); ice_weekend$plot()


ice_settlement <- FeatureEffect$new(
  predictor = predictor,
  feature = "settlement",
  method = "pdp+ice"
); ice_settlement$plot()


shapley <- Shapley$new(
  predictor = predictor,
  x.interest = as.data.frame(tsk_e5.price$data(1))
); shapley$plot()
